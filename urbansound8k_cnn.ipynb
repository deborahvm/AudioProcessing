{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Pacotes utilizados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from keras import models, optimizers, layers, losses, utils\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "'''Função que recebe o endereço do pickle e retorna o conteúdo no formado de numpy array'''\n",
    "def read_pickle(name):\n",
    "    with (open(name, 'rb')) as openfile:\n",
    "        while True:\n",
    "            try:\n",
    "                one_instance = pickle.load(openfile)\n",
    "            except EOFError:\n",
    "                break\n",
    "    one_instance = np.asanyarray(one_instance)\n",
    "    return one_instance\n",
    "\n",
    "'''Função que recebe os espectogramas e os labels e transforma para o formato de entrada da rede aceito pelo Keras'''\n",
    "def pre_processing_datas_to_cnn_format(X, y):\n",
    "    X = X.reshape(X.shape[0],X.shape[1],X.shape[2],1)\n",
    "    y = utils.to_categorical(y)\n",
    "    return X, y\n",
    "\n",
    "'''Função que cria a arquitetura de rede'''\n",
    "def create_model(shape_in, num_classes = 10, dropout_value = 0.5):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    #Primeira camada convolucional\n",
    "    model.add(layers.Conv2D(32, kernel_size=(5,5), activation = 'relu', padding='same', input_shape=(shape_in.shape[0],shape_in.shape[1],shape_in.shape[2]), name = 'conv_1'))\n",
    "\n",
    "    #Primeira camada de pooling\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name = 'pool_1', padding='same'))\n",
    "    \n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    #Segunda camada convolucional\n",
    "    model.add(layers.Conv2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_2'))\n",
    "\n",
    "    #Segunda camada de pooling\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name = 'pool_2', padding='same'))\n",
    "    \n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    #Terceira camada convolucional\n",
    "    model.add(layers.Conv2D(64, kernel_size=(5,5), activation = 'relu', padding='same', name = 'conv_3'))\n",
    "\n",
    "    #Terceira camada de pooling\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name = 'pool_3', padding='same'))\n",
    "    \n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Flatten(name = 'flatten'))\n",
    "    \n",
    "    #Dropout\n",
    "    model.add(layers.Dropout(dropout_value))\n",
    "\n",
    "    #Camada totalmente conectada\n",
    "    model.add(layers.Dense(512, name = 'dense_1', activation='relu'))\n",
    "    \n",
    "    #Dropout\n",
    "    model.add(layers.Dropout(dropout_value))\n",
    "\n",
    "    #Camada de saída\n",
    "    model.add(layers.Dense(num_classes, activation='softmax', name = 'classification'))\n",
    "    \n",
    "    #Para visualizar a arquitetura da rede\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "'''Função que recebe os espectogramas e o endereço do modelo treinado e retorna os características obtidas, que são as saídas da penultima camada da rede'''\n",
    "def extract_features(X_test, path_model):\n",
    "    model = models.load_model(path_model)\n",
    "\n",
    "    intermediate_layer_model = models.Model(inputs=model.input, outputs=model.get_layer(index = -2).output)\n",
    "    features = intermediate_layer_model.predict(X_test)\n",
    "\n",
    "    features = pd.DataFrame(data=features)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Endereços dos pickles contendo os espectogramas e labels\n",
    "path_train = '/data/deborah/UrbanSound8K_temp/log_specs_100_treino.pickle'\n",
    "path_train_labels = '/data/deborah/UrbanSound8K_temp/labels_100_treino.pickle'\n",
    "path_test = '/data/deborah/UrbanSound8K_temp/log_specs_100_teste.pickle'\n",
    "path_test_labels = '/data/deborah/UrbanSound8K_temp/labels_100_teste.pickle'\n",
    "\n",
    "#Nome do modelo que será salvo\n",
    "path_model = 'trained_model_100_augmented.h5'\n",
    "learning_rate = 0.0001\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "dropout_value = 0.5\n",
    "decay_=1e-3\n",
    "\n",
    "X_train = read_pickle(path_train)\n",
    "y_train = read_pickle(path_train_labels)\n",
    "X_test = read_pickle(path_test)\n",
    "y_test = read_pickle(path_test_labels)\n",
    "\n",
    "#Transformando os espectogramas e labels\n",
    "X_train, y_train = pre_processing_datas_to_cnn_format(X_train, y_train)\n",
    "X_test, y_test = pre_processing_datas_to_cnn_format(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 100, 100, 32)      832       \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 50, 50, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 50, 50, 64)        51264     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 25, 25, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 25, 25, 64)        102464    \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               5538304   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "classification (Dense)       (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 5,698,634\n",
      "Trainable params: 5,698,314\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "Train on 55439 samples, validate on 1535 samples\n",
      "Epoch 1/1\n",
      "55439/55439 [==============================] - 17s 302us/step - loss: 3.2485 - acc: 0.1680 - val_loss: 2.0068 - val_acc: 0.3342\n"
     ]
    }
   ],
   "source": [
    "#Criando o modelo e configurando os parâmetros de treinamento\n",
    "model = create_model(X_train[0], num_classes, dropout_value)\n",
    "sgd = optimizers.SGD(lr=learning_rate, decay=decay_)\n",
    "model.compile(loss=losses.categorical_crossentropy, optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "#Treinamento\n",
    "model.fit(X_train, y_train, validation_data = (X_test, y_test), batch_size=batch_size, epochs=epochs, verbose=1)\n",
    "\n",
    "#Salvando o modelo treinado\n",
    "model.save(path_model) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia da rede =  0.33485342019543973\n",
      "Matriz de confusão da rede = \n",
      " [[134   0  26   7  12  67   4  41  15  30]\n",
      " [  0   0   0   7   6   0  15   0   6   0]\n",
      " [  5  10  62  25  37   9   0  15  27  37]\n",
      " [  1   1  16  42  13   2   0   5   7   7]\n",
      " [  0   0   1   0  41   0   0   7   0   1]\n",
      " [ 14   0   4   5   0  36   0  16   6   6]\n",
      " [  0   0   0   1  11   0   1   0   0   0]\n",
      " [  2   0   1   1  13   7   0  23   4   2]\n",
      " [  3  13  39  31   9  36   1  40  88  30]\n",
      " [ 40   8  51  18  15  38   3  67  24  87]]\n"
     ]
    }
   ],
   "source": [
    "#Lendo o modelo salvo após o treinamento\n",
    "model = models.load_model(path_model)\n",
    "\n",
    "#Fazendo a predição dos dados do conjunto de teste com a rede treinada\n",
    "pred = model.predict_classes(X_test)\n",
    "\n",
    "#Imprimindo a acuracia e a matriz de confusão\n",
    "print('Acuracia da rede = ',accuracy_score(pred,np.argmax(y_test,axis=1)))\n",
    "print('Matriz de confusão da rede = \\n', confusion_matrix(pred,np.argmax(y_test,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia da Random Forest =  0.4905537459283388\n",
      "Matriz de confusão da Random Forest = \n",
      " [[106   1  12   5  11  30   0   5   1  14]\n",
      " [  0   0   0   0   0   0   0   0   0   1]\n",
      " [ 15  14  99  12  21  20   1  41  17  41]\n",
      " [  1   1  12 100  17   2   1   2   6   7]\n",
      " [  0   1   2   0  80   2   1  17   1   9]\n",
      " [ 46   0   9   4   0  87   0  49   9   8]\n",
      " [  0   0   0   0   0   0  21   0   0   0]\n",
      " [  0   0   0   1   7   0   0  20   0   1]\n",
      " [  2  13  16   8   2  19   0  40 136  15]\n",
      " [ 29   2  50   7  19  35   0  40   7 104]]\n"
     ]
    }
   ],
   "source": [
    "#Utilizando a rede treinada para extrair as características dos espectogramas\n",
    "X_train_features = extract_features(X_train,path_model)\n",
    "X_test_features = extract_features(X_test,path_model)\n",
    "\n",
    "#Treinando uma Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train_features,np.argmax(y_train,axis=1))\n",
    "\n",
    "#Predição com a Random Forest treinada\n",
    "predicted = clf.predict(X_test_features)\n",
    "\n",
    "#Imprimindo a acuracia e a matriz de confusão\n",
    "print('Acuracia da Random Forest = ',accuracy_score(predicted,np.argmax(y_test,axis=1)))\n",
    "print('Matriz de confusão da Random Forest = \\n',confusion_matrix(predicted,np.argmax(y_test,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
